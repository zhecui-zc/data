{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2adc7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec62f306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Key (replace with your own API key)\n",
    "api_username = \"qa\"\n",
    "# Prefix for API URLs\n",
    "api_prefix = \"https://devcmx.sotiqa.com/api/location/v3/clients?macAddress=\"\n",
    "# The devices that we would like to study\n",
    "rasp_macAddress = \"dc:a6:32:26:67:ab\"\n",
    "samsung_macAddress = \"f4:02:28:5a:28:63\"\n",
    "devices = [\"f4:02:28:5a:28:63\", \"dc:a6:32:26:67:ab\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b64af8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch(api_prefix, devices, df):\n",
    "    \"\"\"\n",
    "    The method fetches the data via the use of the API prefix, key and the year period.\n",
    "    It processes the data and turns it into a json object and returns it.\n",
    "    \"\"\"\n",
    "    now = datetime.now()\n",
    "    later = now + timedelta(minutes=1)\n",
    "    json_objects = []\n",
    "    \n",
    "    while datetime.now() < later:\n",
    "        r = requests.get(api_prefix + devices,  headers={'Authorization': 'Basic cWE6YmxpdHprcmllZ3dlYWtuZXNzZXNlYWRBcDY='})\n",
    "        print(\"CMX STATUS CODE: \" + str(r.status_code))\n",
    "        json_obj = json.loads(r.text)\n",
    "        json_objects.append(df_json_to_pd(json_obj))\n",
    "        time.sleep(1)\n",
    "        \n",
    "    df = pd.concat(json_objects)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86e46aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(fetch(api_prefix,devices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20ac6407",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_json_to_pd(json_object):\n",
    "    print(json_object)\n",
    "    \n",
    "    if json_object == []:\n",
    "        return None\n",
    "    \"\"\"\n",
    "    This method takes as input a json object containing data from a dataset and turns it into a \n",
    "    pandas dataframe.\n",
    "    \"\"\"\n",
    "    objects = []\n",
    "    for device in json_object:\n",
    "        row = {}\n",
    "        row['macAddress'] =  device['macAddress']\n",
    "        row['locationCoordinate_x'] = device['locationCoordinate']['x']\n",
    "        row['locationCoordinate_y'] = device['locationCoordinate']['y']\n",
    "        row['confidenceFactor'] = device['confidenceFactor']\n",
    "        row['maxDetectedRssi'] = device['maxDetectedRssi']['rssi']\n",
    "        row['CMX_lastSeen'] = device['lastSeen']\n",
    "        row['Real_Time'] = datetime.strftime(datetime.now(), '%Y-%m-%d %H:%M:%S')\n",
    "       \n",
    "        objects.append(row)\n",
    "        \n",
    "    return pd.DataFrame(objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffcacc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_csv(df, name):\n",
    "    \"\"\"\n",
    "    This method takes as input a pandas dataframe and a name and saves the dataframe with the given name\n",
    "    as a csv file on the local disk.\n",
    "    \"\"\"\n",
    "    if not df.empty:\n",
    "        df.to_csv('./' + name, index=False)\n",
    "    else:\n",
    "        print('There are no items in the array. No CSV file was created.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4cd89f",
   "metadata": {},
   "source": [
    "Let's collect 2 different datasets containing data about 2 different devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6fc776b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n",
      "CMX STATUS CODE: 200\n",
      "[]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All objects passed were None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m data_frames \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m device \u001b[38;5;129;01min\u001b[39;00m devices:\n\u001b[1;32m----> 4\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_prefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m     data_frames\u001b[38;5;241m.\u001b[39mappend(df)\n",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36mfetch\u001b[1;34m(api_prefix, devices, df)\u001b[0m\n\u001b[0;32m     14\u001b[0m     json_objects\u001b[38;5;241m.\u001b[39mappend(df_json_to_pd(json_obj))\n\u001b[0;32m     15\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_objects\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:347\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcat\u001b[39m(\n\u001b[0;32m    145\u001b[0m     objs: Iterable[NDFrame] \u001b[38;5;241m|\u001b[39m Mapping[Hashable, NDFrame],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    154\u001b[0m     copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    155\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03m    Concatenate pandas objects along a particular axis with optional set logic\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;124;03m    along the other axes.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;124;03m    ValueError: Indexes have overlapping values: ['a']\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:427\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    424\u001b[0m         keys \u001b[38;5;241m=\u001b[39m Index(clean_keys, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 427\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll objects passed were None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    429\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[0;32m    430\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[1;31mValueError\u001b[0m: All objects passed were None"
     ]
    }
   ],
   "source": [
    "data_frames = []\n",
    "\n",
    "for device in devices:\n",
    "    df = fetch(api_prefix, device, [])\n",
    "    print(f\"df = {df}\")\n",
    "    data_frames.append(df)\n",
    "\n",
    "\n",
    "# concatenate all datasets into one pandas dataframe\n",
    "df1 = []\n",
    "if len(data_frames) > 0:\n",
    "    df1 = pd.concat(data_frames)\n",
    "\n",
    "# save the dataframe as a csv file on the disk\n",
    "save_as_csv(df1, 'device_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d8dd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[:-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcd5a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./device_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81816796",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debb0c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c8d398",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d2d27f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff141e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
